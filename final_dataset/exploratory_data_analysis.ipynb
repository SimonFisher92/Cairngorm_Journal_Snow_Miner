{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "def get_dataset():\n",
    "    snapshot_download(\n",
    "        #SimonF92-Snow/Cairngorm_Journal_Snow_APIGPT40_unrefined\n",
    "        repo_id=\"SimonF92-Snow/Cairngorm_Journal_Snow_APIGPT40_unrefined\",\n",
    "        allow_patterns=\"hand_curated/**\",\n",
    "        repo_type=\"dataset\",\n",
    "        local_dir=\"./final_curated_dataset\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "\n",
    "#get_dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#pull in all files from final_curated_dataset/hand_curated and concat\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"./final_curated_dataset/hand_curated/*.csv\")\n",
    "df_list = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)\n",
    "    #print filename\n",
    "    print(f\"Processing file: {file}\")\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ],
   "id": "4b6eaa18a5b9bee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.columns",
   "id": "2dfd637e682d07d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "eccf0c7d3131d135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['location'].value_counts()\n",
   "id": "ba306db6d58e5555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['location'].to_csv('locations.csv')",
   "id": "bb22091c10eb0936",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_mapped_locations = pd.read_csv('mapped_locations.csv')\n",
    "df_mapped_locations['general_location'].value_counts()"
   ],
   "id": "6238060a89f37e37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#merge in on location and specific location\n",
    "df_merged = pd.merge(df, df_mapped_locations, left_on='location', right_on='specific_location', how='left')\n",
    "df_merged = df_merged.drop_duplicates(subset='text', keep='first')\n",
    "df_merged.to_csv('merged_df.csv', index=False)\n"
   ],
   "id": "9c1921734b35a5ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#drop specific location and general location\n",
    "df_merged = df_merged.drop(columns=['specific_location', 'general_location'])\n",
    "df_merged"
   ],
   "id": "66ea77250d5c7e0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#merge in the nice repaired locations\n",
    "df_repaired = pd.read_csv('location_annotated_merged_finished.csv')\n",
    "df_repaired"
   ],
   "id": "16e79ee4c76940b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#merge in on text col\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_repaired[['text', 'general_location', 'specific_location']], on='text', how='left')\n",
    "df_merged['general_location'].value_counts()"
   ],
   "id": "2e37d10e756a2b39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#drop duplicates all rows\n",
    "df_merged = df_merged.drop_duplicates(keep='first')\n",
    "df_merged"
   ],
   "id": "c8ce422ff00ce861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def _to_int(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    x = str(x).strip()\n",
    "    if x in {\"\", \"-\", \"nan\", \"NaN\", \"None\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None, None, None, None\n",
    "\n",
    "    s = str(date_str).strip()\n",
    "\n",
    "    # season format: \"Spring 1893\" (adjust list if needed)\n",
    "    m = re.match(r'^(Spring|Summer|Autumn|Winter)\\s+(\\d{4})$', s, flags=re.I)\n",
    "    if m:\n",
    "        season = m.group(1).capitalize()\n",
    "        year = _to_int(m.group(2))\n",
    "        return year, season, None, None\n",
    "\n",
    "    parts = s.split('/')\n",
    "\n",
    "    if len(parts) == 3:\n",
    "        day = _to_int(parts[0])    # '-' -> None\n",
    "        month = _to_int(parts[1])\n",
    "        year = _to_int(parts[2])\n",
    "        return year, None, month, day\n",
    "\n",
    "    if len(parts) == 2:  # e.g. \"05/1893\" (if it exists in your data)\n",
    "        month = _to_int(parts[0])\n",
    "        year = _to_int(parts[1])\n",
    "        return year, None, month, None\n",
    "\n",
    "    if len(parts) == 1:  # year only\n",
    "        year = _to_int(parts[0])\n",
    "        return year, None, None, None\n",
    "\n",
    "    return None, None, None, None\n",
    "\n",
    "# vectorized (faster than df.apply(axis=1))\n",
    "df_merged[['year', 'season', 'month', 'day']] = (\n",
    "    df_merged['date'].apply(parse_date).apply(pd.Series)\n",
    ")"
   ],
   "id": "e7ef529ee3ccf390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#drop location col\n",
    "df_merged = df_merged.drop(columns=['location'])\n",
    "df_merged"
   ],
   "id": "aa72aa3ef1be9174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#sort on year\n",
    "df_merged = df_merged.sort_values(by=['year', 'month', 'day'])\n",
    "df_merged"
   ],
   "id": "102004b54c0933b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_merged['general_location'].value_counts()",
   "id": "d8daf675c04da9ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#if 'general_location' is \"cairngorm\" change to \"Cairngorms Other\"\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == 'cairngorm', 'general_location'] = 'Cairngorms Other'\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == 'braeriach', 'general_location'] = 'Western Massif'\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == 'cairngorm', 'general_location'] = 'Cairngorms Other'\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == \"beinn a' bhuird\", 'general_location'] = \"Beinn a' Bhuird & Ben Avon\"\n",
    "\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == 'other cairngorms', 'general_location'] = 'Cairngorms Other'\n",
    "df_merged.loc[df_merged['general_location'].str.lower() == 'western massif', 'general_location'] = 'Cairngorms Western Massif'\n",
    "\n",
    "df_merged['general_location'].value_counts()\n",
    "\n"
   ],
   "id": "8c85a1fe33493b23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#change year 1013 to 1913\n",
    "df_merged.loc[df_merged['year'] == 1013, 'year'] = 1913\n",
    "df_merged.loc[df_merged['date'] == '21/10/1013', 'date'] = '21/10/1913'\n",
    "#change 83 to 1983\n",
    "df_merged.loc[df_merged['year'] == 83, 'year'] = 1983\n",
    "df_merged.loc[df_merged['date'] == '02/08/83', 'date'] = '02/08/1983'\n",
    "df_merged"
   ],
   "id": "e9b7d446185c45a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_merged = df_merged.sort_values(by=['year', 'month', 'day'])\n",
    "df_merged"
   ],
   "id": "e879bc395211210e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "location_dict ={\n",
    "    \"Other Highlands\" : np.nan,\n",
    "    \"Lochnagar\" : (56.954291, -3.244078) ,\n",
    "    \"Cairngorms Other\": (57.099690, -3.665600),\n",
    "    \"Cairngorms Western Massif\" : (57.066582, -3.732339) ,\n",
    "    \"Ben Macdui\" : (57.070696, -3.667715),\n",
    "\"Ben Nevis\" : (56.796735, -5.002927) ,\n",
    "\"Beinn a' Bhuird & Ben Avon\": (57.081248, -3.505238),\n",
    "\"Ben Lawers\" : (56.544874, -4.220930) ,\n",
    "\"Central Highlands\" : (56.949668, -4.608764) ,\n",
    "\"Ben Lui\" : (56.396993, -4.810804) ,\n",
    "    \"Torridon & Area\": (57.530301, -5.454877),\n",
    "    \"North West Highlands\": (57.190786, -5.158042),\n",
    "\"Glenshee Area\": (56.876858, -3.373544),\n",
    "    \"Southern Highlands\" : (56.356399, -4.577326),\n",
    "    \"Eastern Highlands\": (57.194888, -3.281276),\n",
    "\n",
    "}"
   ],
   "id": "2faa75329229d8a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#map General Location to dict- add column for coords\n",
    "df_merged['Coordinates'] = df_merged['general_location'].map(location_dict)\n",
    "df_merged"
   ],
   "id": "91a9d856c46ab57c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#if everything matches except text, and the text begings with a match, but one row has longer text, keep the row with the longer text\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def drop_prefix_text_dupes(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"text\",\n",
    "    key_cols=None,          # columns to match on (excluding text)\n",
    "    ignore_cols=None,       # columns to ignore in matching\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    if ignore_cols is None:\n",
    "        ignore_cols = []\n",
    "    if key_cols is None:\n",
    "        key_cols = [c for c in df.columns if c not in ([text_col] + list(ignore_cols))]\n",
    "\n",
    "    def _keep_non_prefix_max(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = group.copy()\n",
    "        g[\"_len\"] = g[text_col].astype(str).str.len()\n",
    "        g = g.sort_values(\"_len\", ascending=False)\n",
    "\n",
    "        texts = g[text_col].astype(str).tolist()\n",
    "        idxs  = g.index.tolist()\n",
    "\n",
    "        kept, dropped = [], set()\n",
    "\n",
    "        for i, (idx, t) in enumerate(zip(idxs, texts)):\n",
    "            if idx in dropped:\n",
    "                continue\n",
    "            kept.append(idx)\n",
    "            for j in range(i + 1, len(texts)):\n",
    "                idx2 = idxs[j]\n",
    "                if idx2 in dropped:\n",
    "                    continue\n",
    "                t2 = texts[j]\n",
    "                if t.startswith(t2):\n",
    "                    dropped.add(idx2)\n",
    "\n",
    "        if verbose and dropped:\n",
    "            key = {c: group.iloc[0][c] for c in key_cols}\n",
    "            print(f\"[Prefix-dedup] key={key} dropped={len(dropped)}\")\n",
    "\n",
    "        return g.loc[kept].drop(columns=\"_len\")\n",
    "\n",
    "    out = (df.groupby(key_cols, dropna=False, group_keys=False)\n",
    "             .apply(_keep_non_prefix_max)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Summary] in={len(df)} out={len(out)} removed={len(df)-len(out)}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# usage:\n",
    "# df2 = drop_prefix_text_dupes_with_logging(df, verbose=True, print_examples=5)\n",
    "\n",
    "df_merged = drop_prefix_text_dupes(df_merged, text_col=\"text\", ignore_cols=[\"score\"], verbose=True)"
   ],
   "id": "15c783dd8ab3aec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_merged = df_merged.sort_values(by=['year', 'month', 'day'])\n",
   "id": "7826aeedf8a81475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#!pip install sweetviz",
   "id": "8bf077c764a666b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#generate sweetviz html report\n",
    "import numpy as np\n",
    "\n",
    "if not hasattr(np, \"VisibleDeprecationWarning\"):\n",
    "    try:\n",
    "        np.VisibleDeprecationWarning = np.exceptions.VisibleDeprecationWarning\n",
    "    except Exception:\n",
    "        np.VisibleDeprecationWarning = DeprecationWarning\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "# df = your pandas DataFrame\n",
    "\n",
    "df_sweetviz = df_merged.copy()\n",
    "df_sweetviz['Coordinates'] = pd.to_numeric(df_sweetviz['Coordinates'], errors='coerce')\n",
    "\n",
    "report = sv.analyze(df_sweetviz)                 # or sv.analyze([df, \"Dataset\"])\n",
    "report.show_html(\"SNOSCOT__report.html\", open_browser=True)"
   ],
   "id": "536f3b258d46aa7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_merged",
   "id": "86a83f13b8ab91d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_merged.to_csv('SNOSCOT_v1_4.csv', index=False)",
   "id": "31b36b6f0dd83f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot number of entries per year\n",
    "import matplotlib.pyplot as plt\n",
    "year_counts = df_merged['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(year_counts.index, year_counts.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Number of Snow Event Entries per Year')\n",
    "#xlim 1850\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()"
   ],
   "id": "900b7891226ee113",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot number of entries per month\n",
    "month_counts = df_merged['month'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(month_counts.index, month_counts.values)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Number of Snow Event Entries per Month')\n",
    "plt.xlim(0, 13)\n",
    "plt.show()\n"
   ],
   "id": "c1b4ba449d1ab173",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#sum the score for the year, then plot each score per year\n",
    "year_score = df_merged.groupby('year')['score'].sum().reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(year_score['year'], year_score['score'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Score')\n",
    "plt.title('Total Snow Score per Year')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()\n"
   ],
   "id": "debcc95236ab13fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#do it for the seasons, grab season from both the season col and the month col (month 12,1,2 = winter etc)\n",
    "def month_to_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "season_scores = {'Winter': 0, 'Spring': 0, 'Summer': 0, 'Autumn': 0}\n",
    "for index, row in df_merged.iterrows():\n",
    "    if pd.notna(row['season']):\n",
    "        season = row['season']\n",
    "    elif pd.notna(row['month']):\n",
    "        season = month_to_season(row['month'])\n",
    "    else:\n",
    "        continue\n",
    "    if season in season_scores:\n",
    "        season_scores[season] += row['score']\n",
    "\n",
    "#plot season scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(season_scores.keys(), season_scores.values())\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Total Score')\n",
    "plt.title('Total Snow Score per Season')\n",
    "plt.show()"
   ],
   "id": "1b13f5aeb94af0bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot a grouped bar chart of season scores per decade\n",
    "decade_season_scores = {}\n",
    "for index, row in df_merged.iterrows():\n",
    "    if pd.notna(row['year']):\n",
    "        decade = (row['year'] // 10) * 10\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if pd.notna(row['season']):\n",
    "        season = row['season']\n",
    "    elif pd.notna(row['month']):\n",
    "        season = month_to_season(row['month'])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if decade not in decade_season_scores:\n",
    "        decade_season_scores[decade] = {'Winter': 0, 'Spring': 0, 'Summer': 0, 'Autumn': 0}\n",
    "\n",
    "    if season in decade_season_scores[decade]:\n",
    "        decade_season_scores[decade][season] += row['score']\n",
    "\n",
    "#plot\n",
    "decades = sorted(decade_season_scores.keys())\n",
    "winter_scores = [decade_season_scores[d]['Winter'] for d in decades]\n",
    "spring_scores = [decade_season_scores[d]['Spring'] for d in decades]\n",
    "summer_scores = [decade_season_scores[d]['Summer'] for d in decades]\n",
    "autumn_scores = [decade_season_scores[d]['Autumn'] for d in decades]\n",
    "\n",
    "x = range(len(decades))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, winter_scores, width=0.2, label='Winter', align='center')\n",
    "plt.bar([i + 0.2 for i in x], spring_scores, width=0.2, label='Spring', align='center')\n",
    "plt.bar([i + 0.4 for i in x], summer_scores, width=0.2, label='Summer', align='center')\n",
    "plt.bar([i + 0.6 for i in x], autumn_scores, width=0.2, label='Autumn', align='center')\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Total Score')\n",
    "plt.title('Total Snow Score per Season by Decade')\n",
    "plt.xticks([i + 0.3 for i in x], decades)\n",
    "plt.legend()\n",
    "#set xlim to 1850 to 2020\n",
    "plt.xlim(9, len(decades))\n",
    "plt.show()\n"
   ],
   "id": "a7c1b6d2a4a84529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# summer mentions of snow on Ben Macdui or Cairngorms Other or Cairngorms Western Massif\n",
    "summer_snow_mentions = df_merged[\n",
    "    (df_merged['score'] > 0) &\n",
    "    (df_merged['general_location'].isin(['Ben Macdui', 'Cairngorms Other', 'Cairngorms Western Massif'])) &\n",
    "    (\n",
    "        (df_merged['season'] == 'Summer') |\n",
    "        (df_merged['month'].isin([6, 7, 8]))\n",
    "    )\n",
    "]\n",
    "\n",
    "summer_snow_mentions = summer_snow_mentions.sort_values(by=['year', 'month', 'day'])\n",
    "summer_snow_mentions\n"
   ],
   "id": "a84de134e5d6fcbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot summer mentions by year\n",
    "summer_year_counts = summer_snow_mentions['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(summer_year_counts.index, summer_year_counts.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Summer Snow Mentions')\n",
    "plt.title('Number of Summer Snow Mentions on Ben Macdui and Cairngorms')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()\n"
   ],
   "id": "6830ce5e53cb6acb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spring_snow_mentions = df_merged[\n",
    "    (df_merged['score'] > 0) &\n",
    "    (df_merged['general_location'].isin(['Ben Macdui', 'Cairngorms Other', 'Cairngorms Western Massif'])) &\n",
    "    (\n",
    "        (df_merged['season'] == 'Spring') |\n",
    "        (df_merged['month'].isin([3, 4, 5]))\n",
    "    )\n",
    "]\n",
    "\n",
    "spring_snow_mentions = spring_snow_mentions.sort_values(by=['year', 'month', 'day'])\n",
    "spring_snow_mentions\n",
    "\n",
    "\n",
    "spring_year_counts = spring_snow_mentions['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(spring_year_counts.index, spring_year_counts.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Spring Snow Mentions')\n",
    "plt.title('Number of Spring Snow Mentions on Ben Macdui and Cairngorms')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "3c29be9648fd84eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "autumn_snow_mentions = df_merged[\n",
    "    (df_merged['score'] > 0) &\n",
    "    (df_merged['general_location'].isin(['Ben Macdui', 'Cairngorms Other', 'Cairngorms Western Massif'])) &\n",
    "    (\n",
    "        (df_merged['season'] == 'Autumn') |\n",
    "        (df_merged['month'].isin([9, 10, 11]))\n",
    "    )\n",
    "]\n",
    "\n",
    "autumn_snow_mentions = autumn_snow_mentions.sort_values(by=['year', 'month', 'day'])\n",
    "autumn_snow_mentions\n",
    "autumn_year_counts = autumn_snow_mentions['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(autumn_year_counts.index, autumn_year_counts.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Autumn Snow Mentions')\n",
    "plt.title('Number of Autumn Snow Mentions on Ben Macdui and Cairngorms')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()"
   ],
   "id": "e801d74a77f80de9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#winter snow mentions\n",
    "winter_snow_mentions = df_merged[\n",
    "    (df_merged['score'] > 0) &\n",
    "    (df_merged['general_location'].isin(['Ben Macdui', 'Cairngorms Other', 'Cairngorms Western Massif'])) &\n",
    "    (\n",
    "        (df_merged['season'] == 'Winter') |\n",
    "        (df_merged['month'].isin([12, 1, 2]))\n",
    "    )\n",
    "]\n",
    "\n",
    "winter_snow_mentions = winter_snow_mentions.sort_values(by=['year', 'month', 'day'])\n",
    "winter_snow_mentions\n",
    "winter_year_counts = winter_snow_mentions['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(winter_year_counts.index, winter_year_counts.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Winter Snow Mentions')\n",
    "plt.title('Number of Winter Snow Mentions on Ben Macdui and Cairngorms')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()\n"
   ],
   "id": "123af2d0ead91393",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#calculate total per-year mentions fpr spring\n",
    "\n",
    "spring_year_counts = spring_snow_mentions['year'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "#smooth this with a rolling average of 5 years\n",
    "spring_year_counts_smoothed = spring_year_counts.rolling(window=5, center=False).mean()\n",
    "spring_year_counts_smoothed = spring_year_counts_smoothed.rolling(window=5, center=False).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(spring_year_counts_smoothed.index, spring_year_counts_smoothed.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Smoothed Number of Spring Snow Mentions')\n",
    "plt.title('Smoothed Number of Spring Snow Mentions on Ben Macdui and Cairngorms')\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "369bf00a8c02bef5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pip install cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "def add_inset_at_lonlat(\n",
    "    fig,\n",
    "    map_ax,\n",
    "    lon,\n",
    "    lat,\n",
    "    plot_inset_fn,\n",
    "    *,\n",
    "    inset_size=(0.12, 0.12),   # (width, height) in figure fraction\n",
    "    pad=(0.0, 0.0),            # (dx, dy) in figure fraction\n",
    "    src_crs=ccrs.PlateCarree(),\n",
    "    inset_facecolor=\"white\",\n",
    "    inset_alpha=0.9,\n",
    "    frame=True,\n",
    "    zorder=20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Place an inset axes at a map location given by (lon, lat), then call plot_inset_fn(inset_ax).\n",
    "    Coordinates are transformed from src_crs into the map projection and then into figure coords.\n",
    "    \"\"\"\n",
    "    # Transform lon/lat to display coords for the map axes\n",
    "    x_disp, y_disp = map_ax.transData.transform(\n",
    "        map_ax.projection.transform_point(lon, lat, src_crs)\n",
    "    )\n",
    "\n",
    "    # Convert display coords to figure fraction coords\n",
    "    x_fig, y_fig = fig.transFigure.inverted().transform((x_disp, y_disp))\n",
    "\n",
    "    w, h = inset_size\n",
    "    dx, dy = pad\n",
    "\n",
    "    # Anchor inset center on the coordinate (you can change to bottom-left anchoring if preferred)\n",
    "    left = x_fig - w / 2 + dx\n",
    "    bottom = y_fig - h / 2 + dy\n",
    "\n",
    "    # Optionally clip to figure bounds\n",
    "    left = np.clip(left, 0.0, 1.0 - w)\n",
    "    bottom = np.clip(bottom, 0.0, 1.0 - h)\n",
    "\n",
    "    inset_ax = fig.add_axes([left, bottom, w, h], zorder=zorder)\n",
    "    inset_ax.set_facecolor(inset_facecolor)\n",
    "    inset_ax.patch.set_alpha(inset_alpha)\n",
    "\n",
    "    if not frame:\n",
    "        for spine in inset_ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "    # Keep inset minimal by default\n",
    "    inset_ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "    # User-supplied function draws the mini-graph into inset_ax\n",
    "    plot_inset_fn(inset_ax)\n",
    "\n",
    "    return inset_ax\n",
    "\n",
    "\n",
    "def plot_scotland_with_insets(\n",
    "    overlays,\n",
    "    *,\n",
    "    extent=(-8.8, -0.5, 54.5, 60.95),  # (lon_min, lon_max, lat_min, lat_max)\n",
    "    figsize=(8, 10),\n",
    "):\n",
    "    \"\"\"\n",
    "    overlays: list of dicts (or tuples) describing each mini-graph.\n",
    "      Required: lon, lat, plot_fn\n",
    "      Optional per item: inset_size, pad, etc.\n",
    "    \"\"\"\n",
    "    proj = ccrs.LambertConformal(central_longitude=-4.0, central_latitude=57.0)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    map_ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "\n",
    "    # Map styling\n",
    "    map_ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    map_ax.add_feature(cfeature.LAND.with_scale(\"10m\"), zorder=0)\n",
    "    map_ax.add_feature(cfeature.OCEAN.with_scale(\"10m\"), zorder=0)\n",
    "    map_ax.add_feature(cfeature.COASTLINE.with_scale(\"10m\"), linewidth=0.8, zorder=2)\n",
    "    map_ax.add_feature(cfeature.BORDERS.with_scale(\"10m\"), linewidth=0.6, zorder=2)\n",
    "    map_ax.add_feature(cfeature.LAKES.with_scale(\"10m\"), alpha=0.5, zorder=1)\n",
    "    map_ax.add_feature(cfeature.RIVERS.with_scale(\"10m\"), linewidth=0.4, zorder=1)\n",
    "\n",
    "    # Optionally: show a marker where each inset is anchored\n",
    "    for item in overlays:\n",
    "        lon, lat = item[\"lon\"], item[\"lat\"]\n",
    "        map_ax.plot(lon, lat, marker=\"o\", markersize=3, transform=ccrs.PlateCarree(), zorder=5)\n",
    "\n",
    "    # Add insets\n",
    "    for item in overlays:\n",
    "        add_inset_at_lonlat(\n",
    "            fig,\n",
    "            map_ax,\n",
    "            item[\"lon\"],\n",
    "            item[\"lat\"],\n",
    "            item[\"plot_fn\"],\n",
    "            inset_size=item.get(\"inset_size\", (0.12, 0.12)),\n",
    "            pad=item.get(\"pad\", (0.0, 0.0)),\n",
    "            inset_facecolor=item.get(\"facecolor\", \"white\"),\n",
    "            inset_alpha=item.get(\"alpha\", 0.9),\n",
    "            frame=item.get(\"frame\", True),\n",
    "        )\n",
    "\n",
    "    return fig, map_ax\n",
    "\n",
    "\n",
    "# --- Example usage ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    def make_sparkline(data):\n",
    "        # Return a function that draws into an axes\n",
    "        def _plot(ax):\n",
    "            ax.plot(data, linewidth=1.2)\n",
    "            ax.set_xlim(0, len(data) - 1)\n",
    "        return _plot\n",
    "\n",
    "    overlays = [\n",
    "        {\"lon\": -4.25, \"lat\": 55.86, \"plot_fn\": make_sparkline(rng.normal(size=30)), \"inset_size\": (0.14, 0.10)},\n",
    "        {\"lon\": -3.19, \"lat\": 55.95, \"plot_fn\": make_sparkline(rng.normal(size=30)), \"pad\": (0.02, 0.02)},\n",
    "        {\"lon\": -2.97, \"lat\": 56.46, \"plot_fn\": make_sparkline(rng.normal(size=30))},\n",
    "        {\"lon\": -5.11, \"lat\": 56.82, \"plot_fn\": make_sparkline(rng.normal(size=30)), \"frame\": False},\n",
    "    ]\n",
    "\n",
    "    fig, ax = plot_scotland_with_insets(overlays)\n",
    "    plt.show()\n"
   ],
   "id": "90a4a0249286bf94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "# pip install cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "def connect_inset_to_lonlat(\n",
    "    fig,\n",
    "    inset_ax,\n",
    "    map_ax,\n",
    "    lon,\n",
    "    lat,\n",
    "    *,\n",
    "    src_crs=ccrs.PlateCarree(),\n",
    "    inset_xy=(0.5, 0.0),     # point on inset (axes coords). (0.5,0)=bottom-center\n",
    "    arrowstyle=\"-\",          # e.g. \"-\" or \"->\"\n",
    "    linewidth=0.8,\n",
    "    color=\"black\",\n",
    "    zorder=50,\n",
    "):\n",
    "    \"\"\"Draw a line from the inset axes to a lon/lat location on the map.\"\"\"\n",
    "    # lon/lat -> map projection coordinates (x,y in map_ax data space)\n",
    "    x, y = map_ax.projection.transform_point(lon, lat, src_crs)\n",
    "\n",
    "    con = ConnectionPatch(\n",
    "        xyA=inset_xy, coordsA=inset_ax.transAxes,\n",
    "        xyB=(x, y),  coordsB=map_ax.transData,\n",
    "        arrowstyle=arrowstyle,\n",
    "        linewidth=linewidth,\n",
    "        color=color,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    fig.add_artist(con)\n",
    "    return con\n",
    "\n",
    "\n",
    "def add_inset_at_lonlat(\n",
    "    fig,\n",
    "    map_ax,\n",
    "    lon,\n",
    "    lat,\n",
    "    plot_inset_fn,\n",
    "    *,\n",
    "    inset_size=(0.12, 0.12),   # (w,h) in figure fraction\n",
    "    pad=(0.0, 0.0),            # (dx,dy) in figure fraction\n",
    "    src_crs=ccrs.PlateCarree(),\n",
    "    connect_to=None,           # None or (lon,lat)\n",
    "    connect_style=None,        # dict for connect_inset_to_lonlat\n",
    "):\n",
    "    # map data -> display -> figure fraction\n",
    "    x_disp, y_disp = map_ax.transData.transform(\n",
    "        map_ax.projection.transform_point(lon, lat, src_crs)\n",
    "    )\n",
    "    x_fig, y_fig = fig.transFigure.inverted().transform((x_disp, y_disp))\n",
    "\n",
    "    w, h = inset_size\n",
    "    dx, dy = pad\n",
    "    left = np.clip(x_fig - w / 2 + dx, 0.0, 1.0 - w)\n",
    "    bottom = np.clip(y_fig - h / 2 + dy, 0.0, 1.0 - h)\n",
    "\n",
    "    inset_ax = fig.add_axes([left, bottom, w, h], zorder=40)\n",
    "    inset_ax.set_facecolor(\"white\")\n",
    "    inset_ax.patch.set_alpha(0.9)\n",
    "    inset_ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "    plot_inset_fn(inset_ax)\n",
    "\n",
    "    # connector line from inset -> target location\n",
    "    if connect_to is not None:\n",
    "        style = dict(arrowstyle=\"-\", linewidth=0.8, color=\"black\", inset_xy=(0.5, 0.0))\n",
    "        if connect_style:\n",
    "            style.update(connect_style)\n",
    "        connect_inset_to_lonlat(fig, inset_ax, map_ax, connect_to[0], connect_to[1], **style)\n",
    "\n",
    "    return inset_ax\n",
    "\n",
    "\n",
    "def plot_scotland_with_insets(\n",
    "    overlays,\n",
    "    *,\n",
    "    extent=(-7.2, -0.5, 55.5, 57.95),  # lon_min, lon_max, lat_min, lat_max\n",
    "    figsize=(8, 10),\n",
    "    use_relief=True,\n",
    "):\n",
    "    proj = ccrs.LambertConformal(central_longitude=-4.0, central_latitude=57.0)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Base map\n",
    "    ax.add_feature(cfeature.OCEAN.with_scale(\"10m\"), zorder=0)\n",
    "    ax.add_feature(cfeature.LAND.with_scale(\"10m\"), zorder=1)\n",
    "\n",
    "    # “Elevation-ish” background option (requires cartopy’s shaded relief raster)\n",
    "    # if use_relief:\n",
    "    #     try:\n",
    "    #         ax.add_feature(cfeature.ShadedRelief(), zorder=0, alpha=0.7)\n",
    "    #     except Exception:\n",
    "    #         # fallback (not elevation, but a decent raster backdrop)\n",
    "    #         ax.stock_img()\n",
    "\n",
    "    ax.add_feature(cfeature.COASTLINE.with_scale(\"10m\"), linewidth=0.8, zorder=5)\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale(\"10m\"), linewidth=0.6, zorder=5)\n",
    "    ax.add_feature(cfeature.RIVERS.with_scale(\"10m\"), linewidth=0.4, zorder=4)\n",
    "\n",
    "    # Inset plots + connectors\n",
    "    for item in overlays:\n",
    "        lon, lat = item[\"lon\"], item[\"lat\"]\n",
    "\n",
    "        # marker at the anchor point (optional)\n",
    "        ax.plot(lon, lat, marker=\"o\", markersize=3, transform=ccrs.PlateCarree(), zorder=10)\n",
    "\n",
    "        add_inset_at_lonlat(\n",
    "            fig, ax, lon, lat,\n",
    "            item[\"plot_fn\"],\n",
    "            inset_size=item.get(\"inset_size\", (0.12, 0.12)),\n",
    "            pad=item.get(\"pad\", (0.0, 0.0)),\n",
    "            connect_to=item.get(\"connect_to\", (lon, lat)),          # default: connect to the same point\n",
    "            connect_style=item.get(\"connect_style\", None),\n",
    "        )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# ---- Example wiring ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    def make_plotter(data):\n",
    "        def _plot(ax):\n",
    "            ax.plot(data, linewidth=1.2)\n",
    "        return _plot\n",
    "\n",
    "    overlays = [\n",
    "        {\n",
    "            \"lon\": -4.25, \"lat\": 55.86,  # Glasgow-ish\n",
    "            \"plot_fn\": make_plotter(rng.normal(size=30)),\n",
    "            \"inset_size\": (0.16, 0.10),\n",
    "            # draw line to a different target location if you want:\n",
    "            \"connect_to\": (-4.25, 56.0),\n",
    "            \"connect_style\": {\"arrowstyle\": \"->\", \"inset_xy\": (0.5, 0.0)},\n",
    "        },\n",
    "        {\n",
    "            \"lon\": -3.19, \"lat\": 55.95,  # Edinburgh-ish\n",
    "            \"plot_fn\": make_plotter(rng.normal(size=30)),\n",
    "            \"pad\": (0.02, 0.02),\n",
    "            \"connect_style\": {\"arrowstyle\": \"-\", \"inset_xy\": (0.0, 0.5)},  # from left-middle\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    fig, ax = plot_scotland_with_insets(overlays, use_relief=True)\n",
    "    plt.show()\n"
   ],
   "id": "f1b1a0f19c7c0394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "import geopandas as gpd\n",
    "import geodatasets\n",
    "from pyproj import Transformer\n",
    "import contextily as cx\n",
    "\n",
    "\n",
    "def lonlat_to_fig_xy(fig, ax, x, y):\n",
    "    x_disp, y_disp = ax.transData.transform((x, y))\n",
    "    return fig.transFigure.inverted().transform((x_disp, y_disp))\n",
    "\n",
    "\n",
    "def add_inset_at_lonlat_webmerc(\n",
    "    fig, ax, lon, lat, plot_fn, *,\n",
    "    transformer, inset_size=(0.12, 0.12), pad=(0, 0),\n",
    "    connect_to=None, connect_style=None\n",
    "):\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    x_fig, y_fig = lonlat_to_fig_xy(fig, ax, x, y)\n",
    "\n",
    "    w, h = inset_size\n",
    "    dx, dy = pad\n",
    "    left = np.clip(x_fig - w/2 + dx, 0, 1 - w)\n",
    "    bottom = np.clip(y_fig - h/2 + dy, 0, 1 - h)\n",
    "\n",
    "    inset_ax = fig.add_axes([left, bottom, w, h], zorder=20)\n",
    "    inset_ax.set_facecolor(\"white\")\n",
    "    inset_ax.patch.set_alpha(0.9)\n",
    "    inset_ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    plot_fn(inset_ax)\n",
    "\n",
    "    if connect_to is None:\n",
    "        connect_to = (lon, lat)\n",
    "    tx, ty = transformer.transform(connect_to[0], connect_to[1])\n",
    "\n",
    "    style = dict(arrowstyle=\"-\", linewidth=0.8, color=\"black\", inset_xy=(0.5, 0.0))\n",
    "    if connect_style:\n",
    "        style.update(connect_style)\n",
    "\n",
    "    con = ConnectionPatch(\n",
    "        xyA=style[\"inset_xy\"], coordsA=inset_ax.transAxes,\n",
    "        xyB=(tx, ty), coordsB=ax.transData,\n",
    "        arrowstyle=style[\"arrowstyle\"],\n",
    "        linewidth=style[\"linewidth\"],\n",
    "        color=style[\"color\"],\n",
    "        zorder=30,\n",
    "    )\n",
    "    fig.add_artist(con)\n",
    "\n",
    "    return inset_ax\n",
    "\n",
    "\n",
    "# ---- boundaries (Natural Earth via geodatasets) ----\n",
    "world_path = geodatasets.get_path(\"naturalearth.land\")  # polygon land; good for backdrop outlines\n",
    "world = gpd.read_file(world_path).to_crs(epsg=3857)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# Highlands-ish extent\n",
    "lon_min, lon_max, lat_min, lat_max = -7.8, -2.2, 56.5, 57.1\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "x0, y0 = transformer.transform(lon_min, lat_min)\n",
    "x1, y1 = transformer.transform(lon_max, lat_max)\n",
    "ax.set_xlim(min(x0, x1), max(x0, x1))\n",
    "ax.set_ylim(min(y0, y1), max(y0, y1))\n",
    "\n",
    "# Terrain-like tiles\n",
    "cx.add_basemap(ax, source=cx.providers.OpenTopoMap)\n",
    "\n",
    "# Optional land outline\n",
    "#world.boundary.plot(ax=ax, linewidth=0.6, color=\"black\", alpha=0.6)\n",
    "\n",
    "# Example overlays\n",
    "rng = np.random.default_rng(0)\n",
    "def make_plotter(data):\n",
    "    def _plot(a):\n",
    "        a.plot(data, linewidth=1.2)\n",
    "    return _plot\n",
    "\n",
    "overlays = [\n",
    "    {\"lon\": -4.25, \"lat\": 57.48, \"plot_fn\": make_plotter(rng.normal(size=30))},\n",
    "    {\"lon\": -5.10, \"lat\": 56.82, \"plot_fn\": make_plotter(rng.normal(size=30)),\n",
    "     \"connect_style\": {\"arrowstyle\": \"->\", \"inset_xy\": (0.5, 0.0)}},\n",
    "]\n",
    "\n",
    "for it in overlays:\n",
    "    add_inset_at_lonlat_webmerc(\n",
    "        fig, ax, it[\"lon\"], it[\"lat\"], it[\"plot_fn\"],\n",
    "        transformer=transformer,\n",
    "        inset_size=it.get(\"inset_size\", (0.14, 0.10)),\n",
    "        pad=it.get(\"pad\", (0.0, 0.0)),\n",
    "        connect_to=it.get(\"connect_to\", None),\n",
    "        connect_style=it.get(\"connect_style\", None),\n",
    "    )\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "d9710e5647183ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad0c72b0353c66f5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
